MODEL?=Qwen/Qwen3-0.6B-GGUF

.PHONY: run build clean

run:
	LD_LIBRARY_PATH=./build/lib ./build/nexa infer $(MODEL)

build: build/llama.cpp
	powershell New-Item -ItemType Directory -Force -Path "build/include","build/lib"
	cmake -B build/llama.cpp-build build/llama.cpp -G "Visual Studio 16 2019" -DBUILD_SHARED_LIBS=ON -DLLAMA_BUILD_TESTS=OFF -DLLAMA_BUILD_TOOLS=OFF -DLLAMA_BUILD_EXAMPLES=OFF -DLLAMA_BUILD_SERVER=OFF -DLLAMA_CURL=OFF
	cmake --build build/llama.cpp-build -j --config Release
	powershell cp ./build/llama.cpp/include/llama.h ./build/include
	powershell cp ./build/llama.cpp/ggml/include/*.h ./build/include
	powershell cp ./build/llama.cpp-build/bin/Release/*.dll ./build/lib

	#g++ -O2 -fPIC -shared -I./build/include -L./build/lib -o ./build/binding-build/libbinding.so ./binding/binding.cpp -Wl,--no-as-needed -lllama -Wl,--as-needed
	#powershell cp ./build/binding-build/*.dll ./build/lib/
	powershell cp ./binding/binding.h ./build/include

	powershell cd runner; go build -o ../build/nexa ./cmd/nexa-cli


build/llama.cpp:
	git clone https://github.com/ggml-org/llama.cpp.git build/llama.cpp

clean:
	rm -rf build/nexa
	rm -rf build/include build/lib
	rm -rf build/binding-build
	rm -rf build/llama.cpp-build

