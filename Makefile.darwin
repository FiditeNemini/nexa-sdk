MODEL?=Qwen/Qwen3-0.6B-GGUF

.PHONY: run build clean

run:
	DYLD_LIBRARY_PATH=./build/lib ./build/nexa infer $(MODEL)

build: build/llama.cpp
	mkdir -p build/include build/lib

	cmake -B build/llama.cpp-build build/llama.cpp -DBUILD_SHARED_LIBS=ON -DLLAMA_BUILD_TESTS=OFF -DLLAMA_BUILD_TOOLS=OFF -DLLAMA_BUILD_EXAMPLES=OFF -DLLAMA_BUILD_SERVER=OFF -DLLAMA_CURL=OFF
	cmake --build build/llama.cpp-build -j --config Release
	cp ./build/llama.cpp/include/llama.h ./build/include
	cp ./build/llama.cpp/ggml/include/*.h ./build/include
	cp ./build/llama.cpp-build/bin/*.dylib ./build/lib

	mkdir -p build/binding-build
	g++ -std=c++11 -O2 -fPIC -shared -I./build/include -L./build/lib -o ./build/binding-build/libbinding.dylib ./binding/binding.cpp -lllama -lggml -lggml-base
	cp ./build/binding-build/*.dylib ./build/lib/
	cp ./binding/binding.h ./build/include

	cd runner && go build -o ../build/nexa ./cmd/nexa-cli


build/llama.cpp:
	git clone https://github.com/ggml-org/llama.cpp.git build/llama.cpp

clean:
	rm -rf build/nexa
	rm -rf build/include build/lib
	rm -rf build/binding-build
	rm -rf build/llama.cpp-build
